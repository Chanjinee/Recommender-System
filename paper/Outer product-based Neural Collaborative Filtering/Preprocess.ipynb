{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- movie-lens 데이터를 불러온 후 전처리하여 pickle파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Parasgr7/Movie-Recommendation-System\n",
    "# AutoEncoders\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# UserID::Gender::Age::Occupation::Zip-code\n",
    "# MovieID::Title::Genres\n",
    "# UserID::MovieID::Rating::Timestamp (5-star scale)\n",
    "\n",
    "# Importing the dataset\n",
    "movies = pd.read_csv('./ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('./ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('./ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user와 item의 수\n",
    "num_users = len(users)\n",
    "num_movies= len(movies)\n",
    "\n",
    "# train, valid, test로 분리\n",
    "train_lst = []\n",
    "val_lst   = []\n",
    "test_lst  = []\n",
    "# 데이터를 userid별로 train, valid, test로 나누어줌\n",
    "for uid in range(num_users):\n",
    "    watches = ratings.loc[ratings[0] == uid] # ratings을 보고 userid와 연결시켜줌\n",
    "    \n",
    "    train_lst.append(watches.iloc[:int(len(watches)*0.7)])\n",
    "    val_lst.append(watches.iloc[int(len(watches)*0.7):int(len(watches)*0.8)])\n",
    "    test_lst.append(watches.iloc[int(len(watches)*0.8):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나누어서 저장함\n",
    "train = pd.concat(train_lst)\n",
    "val   = pd.concat(val_lst)\n",
    "test  = pd.concat(test_lst)\n",
    "train.to_pickle('./data/ml/train.pkl')\n",
    "val.to_pickle('./data/ml/val.pkl')\n",
    "test.to_pickle('./data/ml/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3883)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터에서 user와 movie의 수\n",
    "num_users, num_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3953)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, valid, test의 데이터를 합친 수가 전체와 같은지 확인\n",
    "num_users  = int(max(max(train.values[:,0]), max(val.values[:,0]), max(test.values[:,0]))) + 1\n",
    "num_movies = int(max(max(train.values[:,1]), max(val.values[:,1]), max(test.values[:,1]))) + 1\n",
    "num_users, num_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit ratio / NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lst = []\n",
    "val_lst   = []\n",
    "test_lst  = []\n",
    "neg_lst  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in range(1, num_users+1):\n",
    "    watches = ratings.loc[ratings[0] == uid]\n",
    "    \n",
    "    watched = watches[1].values.tolist()\n",
    "    unwatch = set(range(1, num_movies+1)) - set(watched)\n",
    "    \n",
    "    ns_list = random.sample(unwatch, 100)\n",
    "    \n",
    "    train_lst.append(watches.iloc[:-2])\n",
    "    val_lst.append(watches.iloc[-2])\n",
    "    test_lst.append(watches.iloc[-1])\n",
    "    neg_lst.append(list(ns_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat(train_lst)\n",
    "val   = pd.concat(val_lst, 1).T\n",
    "test  = pd.concat(test_lst, 1).T\n",
    "\n",
    "train.to_pickle('./data/ml/train_score.pkl')\n",
    "val.to_pickle('./data/ml/val_score.pkl')\n",
    "test.to_pickle('./data/ml/test_score.pkl')\n",
    "np.save('./data/ml/neg_score.npy', neg_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
